---
title: "Assignment 13.1"
author: "Vineet Bhardwaj"
date: "19 February 2019"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
#setting the Working directory
setwd("C:/Users/Vineet Bhardwaj/Desktop/BlogFeedback")
getwd()

#loading all the required libraries
library(ggplot2)
library(rstan)
library(rstanarm)
library(class)
library(png)
library(grid)
library(data.table)
library(foreach)
library(MatrixModels)
library(xgboost)
library(ranger)
library(foreach)
library(e1071)
library(FNN)
library(glmnet)

#combine all files except "blogData_train.csv" into one dataframe

setwd("C:/Users/Vineet Bhardwaj/Desktop/BlogFeedback")
filenames=list.files(full.names=TRUE)
allTest=lapply(filenames,function(i){ read.csv(i, header=FALSE)})
blog.test= do.call(rbind.data.frame, allTest)
View(blog.test)

blog.full <- read.csv('C:/Users/Vineet Bhardwaj/Desktop/BlogFeedback/blogData_train.csv', header = FALSE)


#Writing the combined Test Data into one file
write.csv(blog.test, "C:/Users/Vineet Bhardwaj/Desktop/BlogFeedbackNew/blog.test.csv", row.names = F)

#reading the Test combined Data
blog.test <- read.csv("C:/Users/Vineet Bhardwaj/Desktop/BlogFeedbackNew/blog.test.csv",header=TRUE)
View(blog.test)

#As the data doesnot have headers, after understanding the same from the link
#naming the variables in TRAIN Data
att_names <- c( paste(rep(c("comm_","links_"),each=5),
                      c(".tot",".pre.1day",".pre.2day",
                        ".post.1day",".pre.vsday"), sep=""))

names(blog.full) <- c( paste(c("avg","sd","min","max","med"),
                             ".",rep(att_names,each=5),sep=""),
                       att_names,
                       "pubtime", "length", 
                       paste("bagwords_",1:200,sep=""),
                       paste("basetime_",c("Mo","Tu","We","Th","Fr","Sa","Su"),sep=""),
                       paste("pubtime_",c("Mo","Tu","We","Th","Fr","Sa","Su"),sep=""),
                       "_parents",
                       paste(c("min_","max_","avg_"),".comm.parents",sep=""),
                       "comm.next24" )

#naming the variables in TEST Data
names(blog.test) <- names(blog.full)

# drop continous variables without variation
drop = c(8, 13, 28, 33, 38, 40, 43, 50, 278)
blog.full1 <- blog.full[, !(names(blog.full) %in% drop)]
blog.test1 <- blog.test[, !(names(blog.test) %in% drop)]


# log-transform
blog.full1<-data.table(blog.full1)
blog.full1[, comm.next24 := log(1 + comm.next24)]
blog.test1<-data.table(blog.test1)
blog.test1[, comm.next24 := log(1 + comm.next24)]



#Saving the Train and Test Data 
write.csv(blog.test1, "C:/Users/Vineet Bhardwaj/Desktop/BlogFeedbackNew/blogData_Test.csv", row.names = F)
write.csv(blog.full1, "C:/Users/Vineet Bhardwaj/Desktop/BlogFeedbackNew/blogData_Train.csv", row.names = F)

```

```{r}
#reading the Final files after naming the headers
test<- read.csv("C:/Users/Vineet Bhardwaj/Desktop/BlogFeedbackNew/blogData_Test.csv",header=TRUE)
train<-read.csv("C:/Users/Vineet Bhardwaj/Desktop/BlogFeedbackNew/blogData_Train.csv",header=TRUE)

#checking the headers of both the data
str(train)
str(test)
```

```{r}
# error measure
mse = function(y_hat, y) {
  mse = mean((y - y_hat)^2)
  
  return(mse)
}

# create design matrices
train_x = model.Matrix(comm.next24 ~ . - 1, data = train, sparse = F)
train_y = train$comm.next24

test_x = model.Matrix(comm.next24 ~ . - 1, data = test, sparse = F)
test_y = test$comm.next24

train_xgb = xgb.DMatrix(data = as.matrix(train_x), label = train_y)
test_xgb = xgb.DMatrix(data = as.matrix(test_x), label = test_y)

# number of models
n = 5
```

```{r}
# fit XGBoost
pred_xgb = foreach(i = 1:n, .combine = cbind) %do% {
  mdl_xgb = xgboost(data = train_xgb, nround = 500, nthread = 4, max_depth = 6, eta = 0.025, subsample = 0.7, gamma = 3)
  
  return(predict(mdl_xgb, test_xgb))
}

```

```{r}
# fit random forest
pred_rf = foreach(i = 1:n, .combine = cbind) %do% {
  mdl_rf = ranger(comm.next24 ~ ., data = train, num.trees = 1000, mtry = 120, write.forest = T)
  return(predict(mdl_rf, test)$predictions)
  }

```

```{r}
# weighted average

weighted_average = mse(rowMeans(pred_rf) * 0.25 + rowMeans(pred_xgb) * 0.75, test_y)
weighted_average

View(pred_rf)
View(pred_xgb)
```

```{r}
### Stacked Generalization ###
#test<- read.csv("C:/Users/Vineet Bhardwaj/Desktop/BlogFeedbackNew/blogData_Test.csv",header=TRUE)
#train<-read.csv("C:/Users/Vineet Bhardwaj/Desktop/BlogFeedbackNew/blogData_Train.csv",header=TRUE)


train<-data.table(train)
test<-data.table(test)

# error measure
mse = function(y_hat, y) {
  mse = mean((y - y_hat)^2)
  return(mse)
  }

# create design matrices
train_y = train$comm.next24
train_y
test_y = test$comm.next24
test_y

test_x = model.Matrix(comm.next24 ~ . - 1, data = test, sparse = F)
test_x_sparse = model.Matrix(comm.next24 ~ . - 1, data = test, sparse = T)
test_xgb = xgb.DMatrix(data = as.matrix(test_x), label = test_y)


# divide training set into k folds
k = 5
cv_index = 1:nrow(train)
cv_index_split = split(cv_index, cut(seq_along(cv_index), k, labels = FALSE))
```

```{r}
# meta features from kNN
library(Matrix)
meta_knn_test = rep(0, nrow(test))
meta_knn_train = foreach(i = 1:k, .combine = c) %do% {
  # split the raining set into two disjoint sets
  train_index = setdiff(1:nrow(train), cv_index_split[[i]])
  train_set1 = model.Matrix(comm.next24 ~ . - 1, data = train[train_index], sparse = T)
  train_set2 = model.Matrix(comm.next24 ~ . - 1, data = train[cv_index_split[[i]]], sparse = T)
    # level 0 prediction
  meta_pred = knn.reg(train_set1, train_set2, train[train_index]$comm.next24, k = 19)$pred
  meta_knn_test = meta_knn_test + knn.reg(train_set1, test_x_sparse, train[train_index]$comm.next24, k = 19)$pred / k
    return(meta_pred)
  }
```

```{r}
# meta features from LASSO
meta_glm_test = rep(0, nrow(test))
meta_glm_train = foreach(i = 1:k, .combine = c) %do% {
  # split the raining set into two disjoint sets
  train_index = setdiff(1:nrow(train), cv_index_split[[i]])
  train_set1 = model.Matrix(comm.next24 ~ . - 1, data = train[train_index], sparse = T)
  train_set2 = model.Matrix(comm.next24 ~ . - 1, data = train[cv_index_split[[i]]], sparse = T)
  # level 0 prediction
  temp_glm = cv.glmnet(train_set1, train[train_index]$comm.next24, family = "gaussian", alpha = 1)
  meta_pred = predict(temp_glm, newx = train_set2)
  meta_glm_test = meta_glm_test + predict(temp_glm, newx = test_x_sparse) / k
  return(meta_pred)
  }

```

```{r}
# meta features from SVM
meta_svm_test = rep(0, nrow(test))
meta_svm_train = foreach(i = 1:k, .combine = c) %do% {
  # split the raining set into two disjoint sets
  train_index = setdiff(1:nrow(train), cv_index_split[[i]])
  train_set1 = train[train_index]
  train_set2 = train[cv_index_split[[i]]]
    # level 0 prediction
  temp_svm = svm(comm.next24 ~ comm_.pre.1day + comm_.pre.vsday + pubtime + comm_.tot + comm_.post.1day + avg.comm_.pre.vsday + 
                   avg.comm_.pre.1day + med.comm_.pre.1day, data = train_set1, 
                 kernel = "radial", cost = 2, gamma = 0.25)
  meta_pred = predict(temp_svm, train_set2)
  meta_svm_test = meta_svm_test + predict(temp_svm, test) / k
  return(meta_pred)
  }
```

```{r}
# meta features from random forest
meta_rf_test = rep(0, nrow(test))
meta_rf_train = foreach(i = 1:k, .combine = c) %do% {
  # split the raining set into two disjoint sets
  train_index = setdiff(1:nrow(train), cv_index_split[[i]])
  train_set1 = train[train_index]
  train_set2 = train[cv_index_split[[i]]]
  # level 0 prediction
  temp_rf = ranger(comm.next24 ~ ., data = train_set1, num.trees = 500, mtry = 120, write.forest = T)
  meta_pred = predict(temp_rf, train_set2)$predictions
  meta_rf_test = meta_rf_test + predict(temp_rf, test)$predictions / k
  return(meta_pred)
  }
```

```{r}
# meta features from XGBoost
meta_xgb_test = rep(0, nrow(test))
meta_xgb_train = foreach(i = 1:k, .combine = c) %do% {
  # split the raining set into two disjoint sets
  train_index = setdiff(1:nrow(train), cv_index_split[[i]])
  train_set1 = model.Matrix(comm.next24 ~ . - 1, data = train[train_index], sparse = F)
  train_set2 = model.Matrix(comm.next24 ~ . - 1, data = train[cv_index_split[[i]]], sparse = F)
  # xgb data
  train_set1_xgb = xgb.DMatrix(data = as.matrix(train_set1), label = train[train_index]$comm.next24)
  train_set2_xgb = xgb.DMatrix(data = as.matrix(train_set2), label = train[cv_index_split[[i]]]$comm.next24)
  # level 0 prediction
  temp_xgb = xgboost(data = train_set1_xgb, nround = 500, nthread = 4, max_depth = 6, eta = 0.025, subsample = 0.7, gamma = 3)
  meta_pred = predict(temp_xgb, train_set2_xgb)
  meta_xgb_test = meta_xgb_test + predict(temp_xgb, test_xgb) / k
  return(meta_pred)
  }

```

```{r}
# combine meta features
sg_col = c("meta_knn", "meta_glm", "meta_svm", "meta_rf", "meta_xgb", "y")
sg_col

train_y = train$comm.next24
test_y = test$comm.next24

train_sg = data.frame(meta_knn_train, meta_glm_train, meta_svm_train, meta_rf_train, meta_xgb_train, train_y)
test_sg = data.frame(meta_knn_test, meta_glm_test, meta_svm_test, meta_rf_test, meta_xgb_test, test_y)

colnames(train_sg) = sg_col
colnames(test_sg) = sg_col

View(test_sg)
View(train_sg)

write.csv(train_sg, "C:/Users/Vineet Bhardwaj/Desktop/BlogFeedbackNew/train_sg.csv", row.names = F)
write.csv(test_sg, "C:/Users/Vineet Bhardwaj/Desktop/BlogFeedbackNew/test_sg.csv", row.names = F)
```

```{r}
# ensemble with elastic-net regression
train_sg_sparse = model.Matrix(y ~ . - 1, data = train_sg, sparse = T)
View(train_sg_sparse)
test_sg_sparse = model.Matrix(y ~ . - 1, data = test_sg, sparse = T)
mdl_glm = cv.glmnet(train_sg_sparse, train_y, family = "gaussian", alpha = 0.2)
summary(mdl_glm)
pred_glm = predict(mdl_glm, newx = test_sg_sparse, s = "lambda.min")
mse(pred_glm, test_y)


```


## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
